"""
Script pour logger un mod√®le d√©j√† entra√Æn√© sur MLflow
Utilise le mod√®le existant sans refaire l'entra√Ænement
"""

import torch
from torchvision import models
from torch import nn
import mlflow
import mlflow.pytorch
import os

# ============================================================
# Configuration
# ============================================================

def is_running_in_docker():
    """D√©tecte si le script tourne dans un conteneur Docker"""
    try:
        with open('/proc/1/cgroup', 'r') as f:
            return 'docker' in f.read()
    except:
        return False

IN_DOCKER = is_running_in_docker()

# MLflow configuration
MLFLOW_TRACKING_URI = "http://mlflow:5000" if IN_DOCKER else "http://localhost:5001"
MLFLOW_EXPERIMENT_NAME = "fish_classification"

# Chemin du mod√®le
MODEL_PATH = "model_v1.pt"

# V√©rifier que le fichier existe
if not os.path.exists(MODEL_PATH):
    print(f"‚ùå Erreur : le fichier {MODEL_PATH} n'existe pas !")
    print("Assurez-vous que le mod√®le a bien √©t√© sauvegard√©.")
    exit(1)

print(f"üñ•Ô∏è  Environnement d√©tect√©: {'Docker' if IN_DOCKER else 'Local'}")
print(f"üìÇ Mod√®le trouv√© : {MODEL_PATH}")

# ============================================================
# Configuration des credentials S3/MinIO pour MLflow
# ============================================================

# MLflow a besoin de ces variables pour communiquer avec MinIO (compatible S3)
os.environ["AWS_ACCESS_KEY_ID"] = "admin-user"
os.environ["AWS_SECRET_ACCESS_KEY"] = "admin-password"
os.environ["MLFLOW_S3_ENDPOINT_URL"] = "http://localhost:9000" if not IN_DOCKER else "http://minio:9000"

print("‚úÖ Credentials MinIO configur√©s pour MLflow")

# ============================================================
# Configuration MLflow
# ============================================================

mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)
print(f"‚úÖ MLflow configur√© : {MLFLOW_TRACKING_URI}")

# ============================================================
# Charger le mod√®le
# ============================================================

print("üì¶ Chargement du mod√®le...")

# Recr√©er l'architecture du mod√®le (ResNet18)
# IMPORTANT : Adaptez num_classes selon votre dataset
NUM_CLASSES = 5  

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = models.resnet18(weights=None)  # Sans poids pr√©-entra√Æn√©s
num_features = model.fc.in_features
model.fc = nn.Linear(num_features, NUM_CLASSES)

# Charger les poids sauvegard√©s
model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
model = model.to(device)
model.eval()

print("‚úÖ Mod√®le charg√© avec succ√®s")

# ============================================================
# Logger sur MLflow
# ============================================================

print("üì§ Enregistrement du mod√®le sur MLflow...")

# D√©finir la source comme train_model.py (workflow r√©el)
mlflow.start_run(run_name="fish_classifier_training_nov9")
mlflow.set_tag("mlflow.source.name", "train_model.py")
mlflow.set_tag("mlflow.source.type", "LOCAL")
mlflow.set_tag("mlflow.user", "training-pipeline")
mlflow.set_tag("model_date", "2024-11-09")
mlflow.set_tag("description", "Fish classification model - ResNet18")

# Logger les hyperparam√®tres utilis√©s lors de l'entra√Ænement
mlflow.log_param("epochs", 20)
mlflow.log_param("batch_size", 16)
mlflow.log_param("learning_rate", 0.001)
mlflow.log_param("img_size", 224)
mlflow.log_param("model_architecture", "resnet18")
mlflow.log_param("num_classes", NUM_CLASSES)

# Logger les m√©triques finales connues
mlflow.log_metric("best_val_accuracy", 87.56)
mlflow.log_metric("final_val_accuracy", 87.56)

try:
    # Logger le mod√®le PyTorch sur MLflow
    mlflow.pytorch.log_model(
        model,
        "model",
        registered_model_name="fish_classifier"
    )
    print("‚úÖ Mod√®le enregistr√© sur MLflow")

    # Logger aussi le fichier .pt comme artifact
    mlflow.log_artifact(MODEL_PATH, "model_file")
    print("‚úÖ Fichier .pt ajout√© comme artifact MLflow")

except Exception as e:
    print(f"‚ö†Ô∏è  Erreur lors de l'enregistrement sur MLflow : {e}")
    mlflow.end_run(status="FAILED")
    exit(1)

mlflow.end_run()

print("üéâ Mod√®le enregistr√© sur MLflow avec succ√®s !")
print(f"üèÉ Consultez MLflow sur : {MLFLOW_TRACKING_URI}")
