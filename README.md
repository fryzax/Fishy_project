# ğŸŸ Fish Classification - MLOps Project

Projet de classification d'images de poissons utilisant **PyTorch ResNet18** avec un pipeline MLOps complet (MinIO + MySQL + Docker).

## ğŸ“Š RÃ©sultats

- **Classes :** 5 espÃ¨ces (Catfish, Gold Fish, Mudfish, Mullet, Snakehead)
- **Dataset :** 1306 images (1045 train + 261 test)
- **ModÃ¨le :** ResNet18 (transfer learning)
- **Validation Accuracy :** 84.21% (meilleur modÃ¨le)
- **Test Accuracy :** ~70-100% selon Ã©chantillons

## ğŸš€ DÃ©marrage rapide

### 1. DÃ©marrer l'infrastructure et lancer le pipeline complet

```bash
# Infrastructure + interfaces web
docker-compose up -d minio mysql phpmyadmin mlflow

# Puis lancer le pipeline d'entraÃ®nement
docker-compose up --build extraction training
```

Cette commande va automatiquement :
- âœ… DÃ©marrer MinIO et MySQL
- âœ… Attendre que les services soient **healthy** (prÃªts)
- âœ… Lancer `extraction` : crÃ©er la table SQL et extraire les mÃ©tadonnÃ©es depuis MinIO
- âœ… Attendre que extraction soit **terminÃ© avec succÃ¨s**
- âœ… Lancer `training` : tÃ©lÃ©charger les images et entraÃ®ner le modÃ¨le (20 epochs)

### 2. Tester le modÃ¨le entraÃ®nÃ©

```bash
# Important : toujours rebuilder aprÃ¨s modifications de code
docker-compose up --build predict
```

### 3. Commandes individuelles

```bash
# Uniquement l'extraction SQL
docker-compose up --build extraction

# Uniquement le training (nÃ©cessite que extraction ait Ã©tÃ© lancÃ© avant)
docker-compose up --build training

# Lancer une prÃ©diction avec rebuild
docker-compose up --build predict
```

âš ï¸ **Important :** Toujours utiliser `--build` aprÃ¨s avoir modifiÃ© le code Python pour forcer la reconstruction de l'image Docker.

### 4. Interfaces web

| Service | URL | Identifiants |
|---------|-----|--------------|
| MinIO Console | http://localhost:9001 | `admin-user` / `admin-password` |
| phpMyAdmin | http://localhost:8080 | `root` / `root` |
| MLflow | http://localhost:5001 | - |

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MinIO   â”‚â”€â”€â”€â”€â–¶â”‚  Extraction  â”‚â”€â”€â”€â”€â–¶â”‚    MySQL     â”‚â”€â”€â”€â”€â–¶â”‚   Training   â”‚â”€â”€â”€â”€â–¶â”‚  MinIO   â”‚
â”‚ (images) â”‚     â”‚     SQL      â”‚     â”‚ (fish_data)  â”‚     â”‚   (model)    â”‚     â”‚ (model)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚                                       â”‚
                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
                                                                  â–¼                    â–¼
                                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                            â”‚   Predict    â”‚â”€â”€â”€â”€â–¶â”‚  Results â”‚
                                                            â”‚   (test)     â”‚     â”‚          â”‚
                                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Structure du projet

```
.
â”œâ”€â”€ docker-compose.yml           # Orchestration des services
â”œâ”€â”€ Dockerfile                   # Image Python pour les scripts
â”œâ”€â”€ requirements.txt             # DÃ©pendances Python (torch, minio, pymysql, etc.)
â”œâ”€â”€ extraction_creation_sql.py   # CrÃ©ation table + extraction depuis MinIO
â”œâ”€â”€ train_model.py               # EntraÃ®nement du modÃ¨le ResNet18 (20 epochs)
â”œâ”€â”€ predict.py                   # PrÃ©diction sur images de test
â””â”€â”€ FishImgDataset/              # Dataset local (backup)
    â”œâ”€â”€ train/                   # 1045 images d'entraÃ®nement
    â”‚   â”œâ”€â”€ Catfish/
    â”‚   â”œâ”€â”€ Gold Fish/
    â”‚   â”œâ”€â”€ Mudfish/
    â”‚   â”œâ”€â”€ Mullet/
    â”‚   â””â”€â”€ Snakehead/
    â””â”€â”€ test/                    # 261 images de test
        â”œâ”€â”€ Catfish/
        â”œâ”€â”€ Gold Fish/
        â”œâ”€â”€ Mudfish/
        â”œâ”€â”€ Mullet/
        â””â”€â”€ Snakehead/
```

## ğŸ”„ Fonctionnement du pipeline

### 1. Service `extraction`
- Se connecte Ã  MinIO (bucket `dataset-fish`)
- CrÃ©e la table `fish_data` avec le schÃ©ma suivant :
  - `id`, `species_label`, `file_name`, `url_s3`, `split` (train/test), `insert_date`
- Supprime les donnÃ©es existantes (prÃ©vention doublons)
- Parcourt les images dans `train/` et `test/`
- InsÃ¨re les mÃ©tadonnÃ©es dans MySQL avec le champ `split`

### 2. Service `training`  
- **Attend** que `extraction` soit terminÃ© avec succÃ¨s
- RÃ©cupÃ¨re uniquement les images `WHERE split = 'train'` depuis MySQL
- TÃ©lÃ©charge les images depuis MinIO
- Applique un split 80/20 train/validation
- EntraÃ®ne un modÃ¨le **ResNet18** (transfer learning) pendant **20 epochs**
- Calcule Ã  chaque epoch : train loss, validation loss, validation accuracy
- Sauvegarde le meilleur modÃ¨le (meilleure val accuracy)
- Upload le modÃ¨le dans MinIO (bucket `models`) avec timestamp : `model_v1_{timestamp}.pt`

### 3. Service `predict`
- TÃ©lÃ©charge le modÃ¨le entraÃ®nÃ© depuis MinIO
- RÃ©cupÃ¨re 10 images alÃ©atoires `WHERE split = 'test'` depuis MySQL
- Fait des prÃ©dictions et affiche les rÃ©sultats avec confiance
- **Pas de data leakage** : teste uniquement sur le test set

## ğŸ”’ Anti-cheating measures

Le code implÃ©mente plusieurs mesures pour Ã©viter le data leakage :

1. **Split train/test dans la base de donnÃ©es** : champ `split` dans `fish_data`
2. **Training sur train uniquement** : `SELECT ... WHERE split = 'train'`
3. **Validation split** : 80% train, 20% validation sur les donnÃ©es d'entraÃ®nement
4. **Test sur test uniquement** : `SELECT ... WHERE split = 'test'` dans predict.py
5. **Meilleur modÃ¨le basÃ© sur validation accuracy** : Ã©vite l'overfitting

## âš™ï¸ DÃ©pendances automatiques (healthcheck)

Le `docker-compose.yml` gÃ¨re automatiquement les dÃ©pendances :

```yaml
training:
  depends_on:
    minio:
      condition: service_healthy      # MinIO doit Ãªtre prÃªt
    mysql:
      condition: service_healthy      # MySQL doit Ãªtre prÃªt
    extraction:
      condition: service_completed_successfully  # extraction doit avoir rÃ©ussi
```

## ğŸ”§ Configuration

### ParamÃ¨tres d'entraÃ®nement (train_model.py)

```python
EPOCHS = 20              # Nombre d'Ã©poques
BATCH_SIZE = 16         # Taille des batchs
LEARNING_RATE = 0.001   # Taux d'apprentissage
IMG_SIZE = 224          # Taille des images (ResNet18)
```

### Connexions

**MinIO :**
- Endpoint: `minio:9000`
- Access Key: `admin-user`
- Secret Key: `admin-password`
- Buckets: `dataset-fish`, `models`

**MySQL :**
- Host: `mysql`
- User: `root`
- Password: `root`
- Database: `mlops`
- Table: `fish_data`

## ğŸ“ˆ Performances du modÃ¨le

### Training metrics (exemple)
```
Epoch 20/20:
  Train Loss: 0.2847
  Val Loss: 0.5234
  Val Accuracy: 84.21% â­ (meilleur modÃ¨le)
```

### Test results
- PrÃ©cision variable selon les Ã©chantillons : 70-100%
- Confusions principales : 
  - Mudfish âŸ· Catfish
  - Snakehead âŸ· Catfish
- Bonne confiance sur prÃ©dictions correctes (>90%)

## ğŸ› Troubleshooting

### Erreur "cryptography package is required"
âœ… RÃ©solu : `cryptography` ajoutÃ© dans `requirements.txt`

### Message "model_v1.pt tÃ©lÃ©chargÃ©" au lieu du bon nom
âŒ **ProblÃ¨me :** Docker utilise une ancienne image en cache
âœ… **Solution :** Toujours utiliser `--build` :
```bash
docker-compose up --build predict
```

### DonnÃ©es dupliquÃ©es dans MySQL
âœ… RÃ©solu : `DELETE FROM fish_data` avant insertion dans extraction

### Le modÃ¨le "triche" sur les donnÃ©es de test
âœ… RÃ©solu : 
- Ajout du champ `split` dans la table
- Training sur `split = 'train'` uniquement
- Predict sur `split = 'test'` uniquement

## ğŸ§¹ Nettoyage

```bash
# ArrÃªter tous les conteneurs
docker-compose down

# Supprimer aussi les volumes (âš ï¸ efface les donnÃ©es)
docker-compose down -v

# Nettoyer les images Docker
docker system prune -a
```

## ğŸ“ Notes techniques

- **Transfer Learning :** Utilisation des poids prÃ©-entraÃ®nÃ©s IMAGENET1K_V1
- **Optimiseur :** Adam avec LR=0.001
- **Loss :** CrossEntropyLoss
- **Data Augmentation :** RandomHorizontalFlip, Normalize
- **Model Versioning :** Timestamp automatique dans le nom du modÃ¨le
- **Checkpoint :** Sauvegarde du meilleur modÃ¨le basÃ© sur validation accuracy

## ğŸ¯ Prochaines amÃ©liorations

- [ ] IntÃ©gration MLflow pour tracking des expÃ©riences
- [ ] API REST pour prÃ©dictions en temps rÃ©el
- [ ] Data augmentation plus avancÃ©e
- [ ] Test sur l'ensemble complet du test set (pas seulement 10 images)
- [ ] Matrice de confusion et mÃ©triques dÃ©taillÃ©es
- [ ] CI/CD avec GitHub Actions
