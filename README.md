# üêü Fish Classification - MLOps Project

Projet de classification d'images de poissons utilisant **PyTorch ResNet18** avec un pipeline MLOps complet (MinIO + MySQL + Docker) et une interface web interactive.

## üìä R√©sultats

- **Classes :** 5 esp√®ces (Catfish, Gold Fish, Mudfish, Mullet, Snakehead)
- **Dataset :** 1306 images (1045 train + 261 test)
- **Mod√®le :** ResNet18 (transfer learning)
- **Validation Accuracy :** 84.21% (meilleur mod√®le)
- **Test Accuracy :** ~70-100% selon √©chantillons
- **API REST :** FastAPI pour pr√©dictions en temps r√©el
- **Frontend :** React + Vite avec animations aquatiques

## üöÄ D√©marrage rapide

### Option A : Tout d√©marrer en une commande (Recommand√© üéØ)

```bash
# D√©marrer TOUTE l'application (infra + API + frontend)
docker-compose up -d minio mysql phpmyadmin mlflow fish_api frontend

# Acc√©der √† l'application web
open http://localhost:3000
```

‚ú® **Le lendemain, rallumer tout :**
```bash
docker-compose up -d
```

### Option B : D√©marrage √©tape par √©tape

#### 1. Infrastructure de base

```bash
# Infrastructure + interfaces web
docker-compose up -d minio mysql phpmyadmin mlflow
```

#### 2. Pipeline d'entra√Ænement du mod√®le

```bash
# Lancer le pipeline d'entra√Ænement
docker-compose up --build extraction training
```

Cette commande va automatiquement :
- ‚úÖ D√©marrer MinIO et MySQL
- ‚úÖ Attendre que les services soient **healthy** (pr√™ts)
- ‚úÖ Lancer `extraction` : cr√©er la table SQL et extraire les m√©tadonn√©es depuis MinIO
- ‚úÖ Attendre que extraction soit **termin√© avec succ√®s**
- ‚úÖ Lancer `training` : t√©l√©charger les images et entra√Æner le mod√®le (20 epochs)

#### 3. API et Frontend

```bash
# D√©marrer l'API et le Frontend
docker-compose up -d fish_api frontend
```

### 4. Tester le mod√®le (script Python)

```bash
docker-compose up --build predict
```

‚ö†Ô∏è **Important :** Toujours utiliser `--build` apr√®s avoir modifi√© le code Python pour forcer la reconstruction de l'image Docker.

### 5. Interfaces web

| Service | URL | Identifiants |
|---------|-----|--------------|
| **Frontend React** | http://localhost:3000 | - |
| **API FastAPI** | http://localhost:8000 | - |
| MinIO Console | http://localhost:9001 | `admin-user` / `admin-password` |
| phpMyAdmin | http://localhost:8080 | `root` / `root` |
| MLflow | http://localhost:5001 | - |

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  MinIO   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Extraction  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ    MySQL     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Training   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  MinIO   ‚îÇ
‚îÇ (images) ‚îÇ     ‚îÇ     SQL      ‚îÇ     ‚îÇ (fish_data)  ‚îÇ     ‚îÇ   (model)    ‚îÇ     ‚îÇ (model)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                               ‚îÇ                                       ‚îÇ
                                               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îÇ
                                                                  ‚ñº                    ‚ñº
                                                            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                                            ‚îÇ   Predict    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Results ‚îÇ
                                                            ‚îÇ   (test)     ‚îÇ     ‚îÇ          ‚îÇ
                                                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                                                       ‚îÇ
                                                                                       ‚ñº
                                                            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                                            ‚îÇ   FastAPI REST API           ‚îÇ
                                                            ‚îÇ   POST /predict              ‚îÇ
                                                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                                       ‚îÇ
                                                                       ‚ñº
                                                            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                                            ‚îÇ   React Frontend (Vite)      ‚îÇ
                                                            ‚îÇ   - Upload d'images          ‚îÇ
                                                            ‚îÇ   - Animations aquatiques    ‚îÇ
                                                            ‚îÇ   - Affichage r√©sultats      ‚îÇ
                                                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìÅ Structure du projet

```
.
‚îú‚îÄ‚îÄ docker-compose.yml           # Orchestration des services
‚îú‚îÄ‚îÄ Dockerfile                   # Image Python pour les scripts
‚îú‚îÄ‚îÄ requirements.txt             # D√©pendances Python (torch, minio, pymysql, etc.)
‚îú‚îÄ‚îÄ extraction_creation_sql.py   # Cr√©ation table + extraction depuis MinIO
‚îú‚îÄ‚îÄ train_model.py               # Entra√Ænement du mod√®le ResNet18 (20 epochs)
‚îú‚îÄ‚îÄ predict.py                   # Pr√©diction sur images de test
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îî‚îÄ‚îÄ main.py                  # API FastAPI avec endpoint /predict
‚îú‚îÄ‚îÄ frontend/                    # Application React + Vite
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.jsx              # Composant principal avec upload
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/          # Composants UI (Bubbles, SwimmingFish, etc.)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ assets/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ fish-images/     # Images PNG pour le frontend
‚îÇ   ‚îú‚îÄ‚îÄ package.json             # D√©pendances npm
‚îÇ   ‚îî‚îÄ‚îÄ vite.config.js           # Configuration Vite avec proxy
‚îú‚îÄ‚îÄ FishImgDataset/              # Dataset local (backup)
‚îÇ   ‚îú‚îÄ‚îÄ train/                   # 1045 images d'entra√Ænement
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Catfish/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Gold Fish/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Mudfish/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Mullet/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Snakehead/
‚îÇ   ‚îî‚îÄ‚îÄ test/                    # 261 images de test
‚îÇ       ‚îú‚îÄ‚îÄ Catfish/
‚îÇ       ‚îú‚îÄ‚îÄ Gold Fish/
‚îÇ       ‚îú‚îÄ‚îÄ Mudfish/
‚îÇ       ‚îú‚îÄ‚îÄ Mullet/
‚îÇ       ‚îî‚îÄ‚îÄ Snakehead/
‚îî‚îÄ‚îÄ model_v1_1761836094.pt       # Mod√®le entra√Æn√© (versionn√© avec Git LFS)
```

## üîÑ Fonctionnement du pipeline

### 1. Service `extraction`
- Se connecte √† MinIO (bucket `dataset-fish`)
- Cr√©e la table `fish_data` avec le sch√©ma suivant :
  - `id`, `species_label`, `file_name`, `url_s3`, `split` (train/test), `insert_date`
- Supprime les donn√©es existantes (pr√©vention doublons)
- Parcourt les images dans `train/` et `test/`
- Ins√®re les m√©tadonn√©es dans MySQL avec le champ `split`

### 2. Service `training`  
- **Attend** que `extraction` soit termin√© avec succ√®s
- R√©cup√®re uniquement les images `WHERE split = 'train'` depuis MySQL
- T√©l√©charge les images depuis MinIO
- Applique un split 80/20 train/validation
- Entra√Æne un mod√®le **ResNet18** (transfer learning) pendant **20 epochs**
- Calcule √† chaque epoch : train loss, validation loss, validation accuracy
- Sauvegarde le meilleur mod√®le (meilleure val accuracy)
- Upload le mod√®le dans MinIO (bucket `models`) avec timestamp : `model_v1_{timestamp}.pt`

### 3. Service `predict`
- T√©l√©charge le mod√®le entra√Æn√© depuis MinIO
- R√©cup√®re 10 images al√©atoires `WHERE split = 'test'` depuis MySQL
- Fait des pr√©dictions et affiche les r√©sultats avec confiance
- **Pas de data leakage** : teste uniquement sur le test set

### 4. Service `fish_api` (FastAPI)
- API REST pour pr√©dictions en temps r√©el
- Endpoint `POST /predict` : accepte une image (multipart/form-data)
- T√©l√©charge le mod√®le depuis MinIO au d√©marrage
- Retourne la pr√©diction et le score de confiance en JSON
- CORS activ√© pour le frontend (port 3000)

### 5. Frontend React + Vite
- Interface web interactive avec th√®me aquatique
- Upload d'images par glisser-d√©poser ou s√©lection
- Animations de bulles et poissons
- Affichage des r√©sultats avec images et confiance
- Easter egg Kraken (20 clics sur le titre)
- Proxy Vite vers l'API (port 8000)

## üîí Anti-cheating measures

Le code impl√©mente plusieurs mesures pour √©viter le data leakage :

1. **Split train/test dans la base de donn√©es** : champ `split` dans `fish_data`
2. **Training sur train uniquement** : `SELECT ... WHERE split = 'train'`
3. **Validation split** : 80% train, 20% validation sur les donn√©es d'entra√Ænement
4. **Test sur test uniquement** : `SELECT ... WHERE split = 'test'` dans predict.py
5. **Meilleur mod√®le bas√© sur validation accuracy** : √©vite l'overfitting

## ‚öôÔ∏è D√©pendances automatiques (healthcheck)

Le `docker-compose.yml` g√®re automatiquement les d√©pendances :

```yaml
training:
  depends_on:
    minio:
      condition: service_healthy      # MinIO doit √™tre pr√™t
    mysql:
      condition: service_healthy      # MySQL doit √™tre pr√™t
    extraction:
      condition: service_completed_successfully  # extraction doit avoir r√©ussi
```

## üîß Configuration

### Param√®tres d'entra√Ænement (train_model.py)

```python
EPOCHS = 20              # Nombre d'√©poques
BATCH_SIZE = 16         # Taille des batchs
LEARNING_RATE = 0.001   # Taux d'apprentissage
IMG_SIZE = 224          # Taille des images (ResNet18)
```

### Connexions

**MinIO :**
- Endpoint: `minio:9000`
- Access Key: `admin-user`
- Secret Key: `admin-password`
- Buckets: `dataset-fish`, `models`

**MySQL :**
- Host: `mysql`
- User: `root`
- Password: `root`
- Database: `mlops`
- Table: `fish_data`

## üìà Performances du mod√®le

### Training metrics (exemple)
```
Epoch 20/20:
  Train Loss: 0.2847
  Val Loss: 0.5234
  Val Accuracy: 84.21% ‚≠ê (meilleur mod√®le)
```

### Test results
- Pr√©cision variable selon les √©chantillons : 70-100%
- Confusions principales : 
  - Mudfish ‚ü∑ Catfish
  - Snakehead ‚ü∑ Catfish
- Bonne confiance sur pr√©dictions correctes (>90%)

## üêõ Troubleshooting

### Erreur "cryptography package is required"
‚úÖ R√©solu : `cryptography` ajout√© dans `requirements.txt`

### Message "model_v1.pt t√©l√©charg√©" au lieu du bon nom
‚ùå **Probl√®me :** Docker utilise une ancienne image en cache
‚úÖ **Solution :** Toujours utiliser `--build` :
```bash
docker-compose up --build predict
```

### Donn√©es dupliqu√©es dans MySQL
‚úÖ R√©solu : `DELETE FROM fish_data` avant insertion dans extraction

### Le mod√®le "triche" sur les donn√©es de test
‚úÖ R√©solu : 
- Ajout du champ `split` dans la table
- Training sur `split = 'train'` uniquement
- Predict sur `split = 'test'` uniquement

## üßπ Nettoyage

```bash
# Arr√™ter tous les conteneurs
docker-compose down

# Supprimer aussi les volumes (‚ö†Ô∏è efface les donn√©es)
docker-compose down -v

# Nettoyer les images Docker
docker system prune -a
```

## üìù Notes techniques

- **Transfer Learning :** Utilisation des poids pr√©-entra√Æn√©s IMAGENET1K_V1
- **Optimiseur :** Adam avec LR=0.001
- **Loss :** CrossEntropyLoss
- **Data Augmentation :** RandomHorizontalFlip, Normalize
- **Model Versioning :** Timestamp automatique dans le nom du mod√®le
- **Checkpoint :** Sauvegarde du meilleur mod√®le bas√© sur validation accuracy

## üéØ Fonctionnalit√©s

- [x] Pipeline MLOps complet (extraction, training, predict)
- [x] Versioning du mod√®le avec Git LFS
- [x] API REST FastAPI pour pr√©dictions en temps r√©el
- [x] Frontend React avec interface interactive
- [x] Animations et th√®me aquatique
- [x] CORS et proxy configur√©s
- [ ] Int√©gration MLflow pour tracking des exp√©riences
- [ ] Data augmentation plus avanc√©e
- [ ] Test sur l'ensemble complet du test set
- [ ] Matrice de confusion et m√©triques d√©taill√©es
- [ ] CI/CD avec GitHub Actions

## üõ†Ô∏è Technologies utilis√©es

**Backend & MLOps:**
- Python 3.10
- PyTorch 2.9.0 (ResNet18)
- FastAPI (API REST)
- MinIO (stockage S3-compatible)
- MySQL 8.0 (m√©tadonn√©es)
- Docker & Docker Compose
- Git LFS (versioning mod√®le)

**Frontend:**
- React 18.2.0
- Vite 5.0.8
- Axios (HTTP client)
- Tailwind CSS (styling)
