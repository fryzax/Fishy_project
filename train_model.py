# ===============================================
# Script : train_model.py
# Objectif : Entra√Æner un mod√®le CNN pour classifier les poissons
#            Les images sont r√©cup√©r√©es depuis la table SQL
# Auteur : Mathieu + Kirsten
# ===============================================

import os
import io
import pymysql
from minio import Minio
from PIL import Image
from tqdm import tqdm
import torch
from torch import nn, optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader, random_split
from urllib.parse import urljoin
import mlflow
import mlflow.pytorch

# ============================================================
# 1Ô∏è‚É£ Configuration
# ============================================================

# D√©tection de l'environnement (local ou Docker)
# Si on tourne en local, on utilise localhost, sinon les noms de services Docker
import socket

def is_running_in_docker():
    """D√©tecte si le script tourne dans un conteneur Docker"""
    try:
        with open('/proc/1/cgroup', 'r') as f:
            return 'docker' in f.read()
    except:
        return False

IN_DOCKER = is_running_in_docker()

# MinIO configuration
MINIO_ENDPOINT = "minio:9000" if IN_DOCKER else "localhost:9000"
MINIO_ACCESS_KEY = "admin-user"
MINIO_SECRET_KEY = "admin-password"
BUCKET_NAME = "dataset-fish"
MODEL_BUCKET = "models"         # bucket o√π on sauvegarde les mod√®les

# MySQL configuration
MYSQL_HOST = "mysql" if IN_DOCKER else "localhost"
MYSQL_USER = "root"
MYSQL_PASSWORD = "root"
MYSQL_DB = "mlops"

# MLflow configuration
MLFLOW_TRACKING_URI = "http://mlflow:5000" if IN_DOCKER else "http://localhost:5001"
MLFLOW_EXPERIMENT_NAME = "fish_classification"

# Dossiers locaux pour le training
DATA_DIR = "data"
TRAIN_DIR = os.path.join(DATA_DIR, "train")

# Param√®tres d'entra√Ænement
EPOCHS = 20  # Augment√© pour un meilleur entra√Ænement
BATCH_SIZE = 16
LEARNING_RATE = 0.001
IMG_SIZE = 224

print(f"üñ•Ô∏è  Environnement d√©tect√©: {'Docker' if IN_DOCKER else 'Local'}")

# ============================================================
# 2Ô∏è‚É£ Connexion MySQL, MinIO et MLflow
# ============================================================
print("üîå Connexion √† MySQL...")
conn = pymysql.connect(
    host=MYSQL_HOST,
    user=MYSQL_USER,
    password=MYSQL_PASSWORD,
    database=MYSQL_DB
)
cursor = conn.cursor()
print("‚úÖ Connect√© √† MySQL")

print("üîå Connexion √† MinIO...")
minio_client = Minio(
    MINIO_ENDPOINT,
    access_key=MINIO_ACCESS_KEY,
    secret_key=MINIO_SECRET_KEY,
    secure=False
)

# V√©rification des buckets
if not minio_client.bucket_exists(BUCKET_NAME):
    raise ValueError(f"Le bucket '{BUCKET_NAME}' n'existe pas sur MinIO.")
if not minio_client.bucket_exists(MODEL_BUCKET):
    minio_client.make_bucket(MODEL_BUCKET)
    print(f"‚úÖ Bucket '{MODEL_BUCKET}' cr√©√© pour stocker les mod√®les.")

# Cr√©er le bucket mlflow pour les artifacts MLflow
MLFLOW_BUCKET = "mlflow"
if not minio_client.bucket_exists(MLFLOW_BUCKET):
    minio_client.make_bucket(MLFLOW_BUCKET)
    print(f"‚úÖ Bucket '{MLFLOW_BUCKET}' cr√©√© pour les artifacts MLflow.")

print("‚úÖ Connect√© √† MinIO")

# ============================================================
# Configuration des credentials S3/MinIO pour MLflow
# ============================================================
print("üîå Configuration des credentials MLflow pour MinIO...")
os.environ["AWS_ACCESS_KEY_ID"] = MINIO_ACCESS_KEY
os.environ["AWS_SECRET_ACCESS_KEY"] = MINIO_SECRET_KEY
os.environ["MLFLOW_S3_ENDPOINT_URL"] = f"http://minio:9000" if IN_DOCKER else "http://localhost:9000"
print("‚úÖ Credentials configur√©s pour MLflow")

print("üîå Configuration de MLflow...")
mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)
print(f"‚úÖ MLflow configur√© : {MLFLOW_TRACKING_URI}")

# ============================================================
# 3Ô∏è‚É£ Lecture des images depuis la table SQL
# ============================================================
print("üìä Lecture des donn√©es depuis la table fish_data...")

# R√©cup√©rer UNIQUEMENT les images de train
cursor.execute("SELECT species_label, file_name, url_s3 FROM fish_data WHERE split = 'train'")
rows = cursor.fetchall()

print(f"‚úÖ {len(rows)} images de training trouv√©es dans la base de donn√©es")

# ============================================================
# 4Ô∏è‚É£ T√©l√©chargement des images depuis MinIO bas√© sur SQL
# ============================================================
print("üì¶ T√©l√©chargement des images depuis MinIO (bas√© sur la table SQL)...")

os.makedirs(TRAIN_DIR, exist_ok=True)

for label, file_name, url_s3 in tqdm(rows, desc="Downloading images"):
    # Reconstituer le chemin dans MinIO : train/label/filename
    key = f"train/{label}/{file_name}"

    # Cr√©e un dossier local par label
    label_dir = os.path.join(TRAIN_DIR, label)
    os.makedirs(label_dir, exist_ok=True)

    # Chemin complet de sortie
    local_path = os.path.join(label_dir, file_name)

    # Ne t√©l√©charger que si le fichier n'existe pas d√©j√†
    if not os.path.exists(local_path):
        try:
            minio_client.fget_object(BUCKET_NAME, key, local_path)
        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur pour {key}: {e}")

cursor.close()
conn.close()

print("‚úÖ T√©l√©chargement termin√©.")

# ============================================================
# 5Ô∏è‚É£ Pr√©paration des donn√©es PyTorch
# ============================================================

transform = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

dataset = datasets.ImageFolder(root=TRAIN_DIR, transform=transform)

# Split train/val
train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)

print(f"üìä Dataset pr√™t : {len(train_dataset)} train / {len(val_dataset)} val images")

# ============================================================
# 6Ô∏è‚É£ Construction du mod√®le CNN
# ============================================================

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Utilisation d'un mod√®le pr√©-entra√Æn√© (Transfer Learning)
model = models.resnet18(weights="IMAGENET1K_V1")
num_features = model.fc.in_features
model.fc = nn.Linear(num_features, len(dataset.classes))  # adapte √† ton nb d'esp√®ces
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

# ============================================================
# 7Ô∏è‚É£ Entra√Ænement avec validation
# ============================================================
print("üöÄ D√©but de l'entra√Ænement...")

best_val_acc = 0.0
best_model_path = "best_model.pt"

# D√©marrer une run MLflow
mlflow.start_run()

# Logger les hyperparam√®tres
mlflow.log_param("epochs", EPOCHS)
mlflow.log_param("batch_size", BATCH_SIZE)
mlflow.log_param("learning_rate", LEARNING_RATE)
mlflow.log_param("img_size", IMG_SIZE)
mlflow.log_param("model_architecture", "resnet18")
mlflow.log_param("num_classes", len(dataset.classes))
mlflow.log_param("train_size", len(train_dataset))
mlflow.log_param("val_size", len(val_dataset))

for epoch in range(EPOCHS):
    # Phase d'entra√Ænement
    model.train()
    running_loss = 0.0
    for images, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{EPOCHS} [Train]", leave=False):
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

    train_loss = running_loss / len(train_loader)

    # Phase de validation
    model.eval()
    val_loss = 0.0
    correct = 0
    total = 0

    with torch.no_grad():
        for images, labels in tqdm(val_loader, desc=f"Epoch {epoch+1}/{EPOCHS} [Val]", leave=False):
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            val_loss += loss.item()

            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    val_loss = val_loss / len(val_loader)
    val_accuracy = 100 * correct / total

    print(f"üìä Epoch {epoch+1}/{EPOCHS} - Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_accuracy:.2f}%")

    # Logger les m√©triques sur MLflow √† chaque epoch
    mlflow.log_metric("train_loss", train_loss, step=epoch)
    mlflow.log_metric("val_loss", val_loss, step=epoch)
    mlflow.log_metric("val_accuracy", val_accuracy, step=epoch)

    # Sauvegarder le meilleur mod√®le
    if val_accuracy > best_val_acc:
        best_val_acc = val_accuracy
        torch.save(model.state_dict(), best_model_path)
        print(f"   ‚≠ê Nouveau meilleur mod√®le sauvegard√© ! (Val Acc: {val_accuracy:.2f}%)")
        mlflow.log_metric("best_val_accuracy", best_val_acc)

print(f"‚úÖ Entra√Ænement termin√©. Meilleure pr√©cision validation : {best_val_acc:.2f}%")

# ============================================================
# 8Ô∏è‚É£ Sauvegarde du meilleur mod√®le
# ============================================================

MODEL_PATH = "model_v1.pt"
# Copier le meilleur mod√®le vers le nom final
import shutil
import time
shutil.copy(best_model_path, MODEL_PATH)
print(f"üíæ Meilleur mod√®le sauvegard√© localement sous {MODEL_PATH} (Val Acc: {best_val_acc:.2f}%)")

# ============================================================
# 9Ô∏è‚É£ Logger le mod√®le sur MLflow
# ============================================================

print("üì§ Enregistrement du mod√®le sur MLflow...")
try:
    # Logger le mod√®le PyTorch sur MLflow
    mlflow.pytorch.log_model(
        model,
        "model",
        registered_model_name="fish_classifier"
    )
    print("‚úÖ Mod√®le enregistr√© sur MLflow")

    # Logger aussi le fichier .pt comme artifact
    mlflow.log_artifact(MODEL_PATH, "model_file")
    print("‚úÖ Fichier .pt ajout√© comme artifact MLflow")

except Exception as e:
    print(f"‚ö†Ô∏è  Erreur lors de l'enregistrement sur MLflow : {e}")

# ============================================================
# üîü Upload du mod√®le vers MinIO
# ============================================================

try:
    # Utiliser un nom unique avec timestamp pour √©viter les conflits
    timestamp = int(time.time())
    model_name = f"model_v1_{timestamp}.pt"

    # Logger le nom du mod√®le MinIO sur MLflow
    mlflow.log_param("minio_model_name", model_name)

    # Upload avec un nouveau nom pour √©viter les deadlocks
    with open(MODEL_PATH, 'rb') as file_data:
        file_stat = os.stat(MODEL_PATH)
        minio_client.put_object(
            MODEL_BUCKET,
            model_name,
            file_data,
            file_stat.st_size,
        )
    print(f"‚úÖ Mod√®le envoy√© sur MinIO : bucket='{MODEL_BUCKET}', objet='{model_name}'")
except Exception as e:
    print(f"‚ö†Ô∏è  Erreur lors de l'upload vers MinIO : {e}")
    print(f"   Le mod√®le reste disponible localement : {MODEL_PATH}")

# Terminer la run MLflow
mlflow.end_run()

print("üéâ Entra√Ænement termin√© avec succ√®s !")
